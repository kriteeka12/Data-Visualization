{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiGeptVPRRyuYjNDPzzE1w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kriteeka12/Data-Visualization/blob/main/Model_Evaluation_and_Hyperparameter_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "No4D0gpallL3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Tit-PglUls8l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'SVM': SVC()\n",
        "}\n"
      ],
      "metadata": {
        "id": "J9WH72vQlvOh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(name, model):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"\\n{name} Performance:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
        "    print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "    print(\"F1-Score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "for name, model in models.items():\n",
        "    evaluate_model(name, model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA7Jk9Ccl8j4",
        "outputId": "f444ad58-11e5-49b4-d049-9938b6596ad1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Performance:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n",
            "\n",
            "Decision Tree Performance:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n",
            "\n",
            "Random Forest Performance:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n",
            "\n",
            "SVM Performance:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(SVC(), param_grid, cv=3, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest Params (SVM - GridSearch):\", grid_search.best_params_)\n",
        "evaluate_model(\"Tuned SVM (GridSearchCV)\", grid_search.best_estimator_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKpOmVRTmA0A",
        "outputId": "a9a751fc-1d84-45f0-a694-6d1dd045ecc1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Params (SVM - GridSearch): {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "\n",
            "Tuned SVM (GridSearchCV) Performance:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import randint\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_depth': randint(2, 10),\n",
        "    'min_samples_split': randint(2, 10),\n",
        "    'min_samples_leaf': randint(1, 10)\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist,\n",
        "                                   n_iter=10, cv=3, scoring='accuracy', random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest Params (RandomForest - RandomizedSearch):\", random_search.best_params_)\n",
        "evaluate_model(\"Tuned RandomForest (RandomizedSearchCV)\", random_search.best_estimator_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZH2Wb-cmD6y",
        "outputId": "638212f9-0530-463a-d0d4-dcbff3981ef1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Params (RandomForest - RandomizedSearch): {'max_depth': 8, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 124}\n",
            "\n",
            "Tuned RandomForest (RandomizedSearchCV) Performance:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "def evaluate_and_store(name, model):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred, average='macro'),\n",
        "        'Recall': recall_score(y_test, y_pred, average='macro'),\n",
        "        'F1-Score': f1_score(y_test, y_pred, average='macro')\n",
        "    })\n",
        "\n",
        "# Store results\n",
        "for name, model in models.items():\n",
        "    evaluate_and_store(name, model)\n",
        "\n",
        "evaluate_and_store(\"Tuned SVM\", grid_search.best_estimator_)\n",
        "evaluate_and_store(\"Tuned RandomForest\", random_search.best_estimator_)\n",
        "\n",
        "# Convert to DataFrame\n",
        "results_df = pd.DataFrame(results).sort_values(by='F1-Score', ascending=False)\n",
        "print(\"\\nModel Comparison:\\n\", results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OINZjQu8mMZQ",
        "outputId": "e076101f-a9bc-410a-ae00-bf28ae976aea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Comparison:\n",
            "                  Model  Accuracy  Precision  Recall  F1-Score\n",
            "0  Logistic Regression       1.0        1.0     1.0       1.0\n",
            "1        Decision Tree       1.0        1.0     1.0       1.0\n",
            "2        Random Forest       1.0        1.0     1.0       1.0\n",
            "3                  SVM       1.0        1.0     1.0       1.0\n",
            "4            Tuned SVM       1.0        1.0     1.0       1.0\n",
            "5   Tuned RandomForest       1.0        1.0     1.0       1.0\n"
          ]
        }
      ]
    }
  ]
}